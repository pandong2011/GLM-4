# basic_demo
# use vllm
# vllm>=0.5.0

torch>=2.3.0
torchvision>=0.18.0
transformers==4.40.0
huggingface-hub>=0.23.1
sentencepiece>=0.2.0
pydantic>=2.7.1
timm>=0.9.16
tiktoken>=0.7.0
accelerate>=0.30.1
sentence_transformers>=2.7.0

# web demo
gradio>=4.33.0

# openai demo
openai>=1.34.0
einops>=0.7.0
sse-starlette>=2.1.0

# INT4
# bitsandbytes>=0.43.1
bitsandbytes>=0.42.0

# PEFT model, not need if you don't use PEFT finetune model.
# peft>=0.11.0



# composite_demo
# Please install the requirments.txt in basic_demo first!
# use vllm
# vllm>=0.4.3

# ipykernel>=6.26.0
# ipython>=8.18.1
# jupyter_client>=8.6.0

langchain>=0.2.1
langchain-community>=0.2.1

matplotlib>=3.9.0
pillow>=10.1.0
pymupdf>=1.24.5
# python-docx>=1.1.2
# python-pptx>=0.6.23
# pyyaml>=6.0.1
requests>=2.31.0
streamlit>=1.35.0
transformers==4.40.0
zhipuai>=2.1.0



# finetune_demo
jieba>=0.42.1
datasets>=2.20.0
peft>=0.11.1
deepspeed>=0.14.3
nltk==3.8.1
rouge_chinese>=1.0.3
ruamel.yaml>=0.18.6



# intel_device_demo
# cmake>=3.29.5.1
# git+https://github.com/intel/neural-speed.git@main#egg=neural-speed
# intel-extension-for-transformers>=1.4.2

# optimum>=1.20.0
# optimum-intel @ git+https://github.com/huggingface/optimum-intel.git@c1ee8ac0864e25e22ea56b5a37a35451531da0e6